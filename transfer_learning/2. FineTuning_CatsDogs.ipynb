{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bNBLfCiP9OT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "ROOT_DIR = '/content'\n",
        "\n",
        "DATA_ROOT_DIR = os.path.join(ROOT_DIR, 'cats_and_dogs_filtered')\n",
        "\n",
        "TRAIN_DATA_ROOT_DIR = os.path.join(DATA_ROOT_DIR, 'train')\n",
        "\n",
        "VALIDATION_DATA_ROOT_DIR = os.path.join(DATA_ROOT_DIR, 'validation')"
      ],
      "metadata": {
        "id": "SiPcB5w8VTgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "print(f\"using PyTorch version: {torch.__version__}, Device: {DEVICE}\")"
      ],
      "metadata": {
        "id": "VgftZtoUf6YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운로드\n",
        "\n",
        "!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "id": "zXrYTY_YUjCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "if os.path.exists('/content/cats_and_dogs_filtered/'):    # 작업 디렉토리는 cats_and_dogs_filtered\n",
        "\n",
        "    shutil.rmtree('/content/cats_and_dogs_filtered/')\n",
        "    print('/content/cats_and_dogs_filtered/  is removed !!!')"
      ],
      "metadata": {
        "id": "MlBzWloKUv5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 압축파일 풀기\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/cats_and_dogs_filtered.zip', 'r') as target_file:\n",
        "\n",
        "    target_file.extractall('/content/')"
      ],
      "metadata": {
        "id": "rfRPgggOUv0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# train data 개수\n",
        "\n",
        "train_cats_list = os.listdir('/content/cats_and_dogs_filtered/train/cats/')\n",
        "\n",
        "train_dogs_list = os.listdir('/content/cats_and_dogs_filtered/train/dogs/')\n",
        "\n",
        "# validation data 개수\n",
        "\n",
        "test_cats_list = os.listdir('/content/cats_and_dogs_filtered/validation/cats/')\n",
        "\n",
        "test_dogs_list = os.listdir('/content/cats_and_dogs_filtered/validation/dogs/')\n",
        "\n",
        "print(len(train_cats_list), len(train_dogs_list))\n",
        "\n",
        "print(len(test_cats_list), len(test_dogs_list))"
      ],
      "metadata": {
        "id": "62yhoMD1UvvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_config = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                   transforms.RandomHorizontalFlip(),\n",
        "                                   transforms.ToTensor()])\n",
        "\n",
        "validation_config = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                        transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "UqyEBd6rU8vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder('/content/cats_and_dogs_filtered/train/', train_config)\n",
        "\n",
        "validation_dataset = datasets.ImageFolder('/content/cats_and_dogs_filtered/validation/', validation_config)\n",
        "\n",
        "test_dataset = datasets.ImageFolder('/content/cats_and_dogs_filtered/validation/', validation_config)"
      ],
      "metadata": {
        "id": "8m_eV0f-X2qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "validation_dataset_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "test_dataset_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "UBVvaJJTdpey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개의 배치를 추출\n",
        "\n",
        "images, labels = next(iter(train_dataset_loader))"
      ],
      "metadata": {
        "id": "j5f8fsACeDHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ImageFolder의 속성 값인 class_to_idx를 할당\n",
        "\n",
        "labels_map = { v:k  for k, v in train_dataset.class_to_idx.items() }\n",
        "\n",
        "figure = plt.figure(figsize=(6, 7))\n",
        "\n",
        "cols, rows = 4, 4\n",
        "\n",
        "# 이미지 출력\n",
        "\n",
        "for i in range(1, cols*rows+1):\n",
        "\n",
        "    sample_idx = torch.randint(len(images), size=(1,)).item()\n",
        "    img, label = images[sample_idx], labels[sample_idx].item()\n",
        "\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # 본래 이미지의 shape은 (3, 224, 224) 인데,\n",
        "    # 이를 imshow() 함수로 이미지 시각화 하기 위하여 (224, 224, 3)으로 shape 변경을 한 후 시각화\n",
        "    plt.imshow(torch.permute(img, (1, 2, 0)))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AwwznNyoeDDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
        "\n",
        "print(pretrained_model)"
      ],
      "metadata": {
        "id": "MWMm_XpwX7_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTransferLearningModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_model, feature_extractor):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        if (feature_extractor):\n",
        "            for param in pretrained_model.parameters():\n",
        "                param.require_grad = False\n",
        "\n",
        "        # vision transformer 에서의 classifier 부분은 heads 로 지정\n",
        "        pretrained_model.heads = torch.nn.Sequential(\n",
        "            torch.nn.Linear(pretrained_model.heads[0].in_features, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "        self.model = pretrained_model\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        logits = self.model(data)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "933p5o9nYC_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = False  # True: Feature Extractor,  False: Fine Tuning\n",
        "\n",
        "model = MyTransferLearningModel(pretrained_model, feature_extractor).to(DEVICE)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-6)"
      ],
      "metadata": {
        "id": "6VHqTbytcwCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train(dataloader, model, loss_function, optimizer):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_loss_sum = train_correct = train_total = 0\n",
        "\n",
        "    total_train_batch = len(dataloader)\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "\n",
        "        x_train = images.to(DEVICE)\n",
        "        y_train = labels.to(DEVICE)\n",
        "\n",
        "        outputs = model(x_train)\n",
        "        loss = loss_function(outputs, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_sum += loss.item()\n",
        "\n",
        "        train_total += y_train.size(0)\n",
        "        train_correct += ((torch.argmax(outputs, 1)==y_train)).sum().item()\n",
        "\n",
        "    train_avg_loss = train_loss_sum / total_train_batch\n",
        "    train_avg_accuracy = 100*train_correct / train_total\n",
        "\n",
        "    return (train_avg_loss, train_avg_accuracy)"
      ],
      "metadata": {
        "id": "VnsCH8YvgNYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_evaluate(dataloader, model, loss_function, optimizer):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        val_loss_sum = val_correct = val_total = 0\n",
        "\n",
        "        total_val_batch = len(dataloader)\n",
        "\n",
        "        for images, labels in dataloader:\n",
        "\n",
        "            x_val = images.to(DEVICE)\n",
        "            y_val = labels.to(DEVICE)\n",
        "\n",
        "            outputs = model(x_val)\n",
        "            loss = loss_function(outputs, y_val)\n",
        "\n",
        "            val_loss_sum += loss.item()\n",
        "\n",
        "            val_total += y_val.size(0)\n",
        "            val_correct += ((torch.argmax(outputs, 1)==y_val)).sum().item()\n",
        "\n",
        "        val_avg_loss = val_loss_sum / total_val_batch\n",
        "        val_avg_accuracy = 100*val_correct / val_total\n",
        "\n",
        "    return (val_avg_loss, val_avg_accuracy)"
      ],
      "metadata": {
        "id": "FO2CQ5TjgY74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_test(dataloader, model):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        test_loss_sum = test_correct = test_total = 0\n",
        "\n",
        "        total_test_batch = len(dataloader)\n",
        "\n",
        "        for images, labels in dataloader:\n",
        "\n",
        "            x_test = images.to(DEVICE)\n",
        "            y_test = labels.to(DEVICE)\n",
        "\n",
        "            outputs = model(x_test)\n",
        "            loss = loss_function(outputs, y_test)\n",
        "\n",
        "            test_loss_sum += loss.item()\n",
        "\n",
        "            test_total += y_test.size(0)\n",
        "            test_correct += ((torch.argmax(outputs, 1)==y_test)).sum().item()\n",
        "\n",
        "        test_avg_loss = test_loss_sum / total_test_batch\n",
        "        test_avg_accuracy = 100*test_correct / test_total\n",
        "\n",
        "        print('accuracy:', test_avg_accuracy)\n",
        "        print('loss:', test_avg_loss)"
      ],
      "metadata": {
        "id": "BFGZVHLsRCr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "train_loss_list = []\n",
        "train_accuracy_list = []\n",
        "\n",
        "val_loss_list = []\n",
        "val_accuracy_list = []\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    #==============  model train  ================\n",
        "    train_avg_loss, train_avg_accuracy = model_train(train_dataset_loader, model, loss_function, optimizer)\n",
        "\n",
        "    train_loss_list.append(train_avg_loss)\n",
        "    train_accuracy_list.append(train_avg_accuracy)\n",
        "    #=============================================\n",
        "\n",
        "    #============  model evaluation  ==============\n",
        "    val_avg_loss, val_avg_accuracy = model_evaluate(validation_dataset_loader, model, loss_function, optimizer)\n",
        "\n",
        "    val_loss_list.append(val_avg_loss)\n",
        "    val_accuracy_list.append(val_avg_accuracy)\n",
        "    #============  model evaluation  ==============\n",
        "\n",
        "    print('epoch:', '%02d' % (epoch + 1),\n",
        "          'train loss =', '{:.3f}'.format(train_avg_loss), 'train acc =', '{:.3f}'.format(train_avg_accuracy),\n",
        "          'val loss =', '{:.3f}'.format(val_avg_loss), 'val acc =', '{:.3f}'.format(val_avg_accuracy))\n",
        "\n",
        "end_time = datetime.now()\n",
        "\n",
        "print('elapsed time => ', end_time-start_time)"
      ],
      "metadata": {
        "id": "SK0v-dR4YKc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset 으로 정확도 및 오차 테스트\n",
        "\n",
        "model_test(test_dataset_loader, model)"
      ],
      "metadata": {
        "id": "1E07YvjeSz0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('Loss Trend')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n",
        "\n",
        "plt.plot(train_loss_list, label='train loss')\n",
        "plt.plot(val_loss_list, label='validation loss')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BybzM1BcQbmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('Accuracy Trend')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.grid()\n",
        "\n",
        "plt.plot(train_accuracy_list, label='train accuracy')\n",
        "plt.plot(val_accuracy_list, label='validation accuracy')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hiw5fcbPQ0rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Loss Trend')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n",
        "plt.plot(train_loss_list, label='train')\n",
        "plt.plot(val_loss_list, label='validation')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('Accuracy Trend')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.grid()\n",
        "plt.plot(train_accuracy_list, label='train')\n",
        "plt.plot(val_accuracy_list, label='validation')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HC9MxFZPS3qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKvvjoqcRkBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}