{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 증강(Data Augmentation)\n",
        "\n"
      ],
      "metadata": {
        "id": "Pkt_A4M-4zXM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0IB_UGg4VlG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.image as image\n",
        "import numpy as np\n",
        "\n",
        "img_path = keras.utils.get_file(\n",
        "    fname=\"cat.jpg\",\n",
        "    origin=\"https://img-datasets.s3.amazonaws.com/cat.jpg\")\n",
        "img = image.imread(img_path)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#augmentation이 적용된 image들을 시각화 해주는 함수\n",
        "def show_aug_image_batch(image, generator, n_images=4):\n",
        "\n",
        "    # ImageDataGenerator는 여러개의 image를 입력으로 받기 때문에 4차원으로 입력 해야함.\n",
        "    image_batch = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # featurewise_center or featurewise_std_normalization or zca_whitening 가 True일때만 fit 해주어야함\n",
        "    # generator.fit(image_batch)\n",
        "    # flow로 image batch를 generator에 넣어주어야함.\n",
        "    data_gen_iter = generator.flow(image_batch)\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=n_images, figsize=(24, 8))\n",
        "\n",
        "    for i in range(n_images):\n",
        "    \t#generator에 batch size 만큼 augmentation 적용(매번 적용이 다름)\n",
        "        aug_image_batch = next(data_gen_iter)\n",
        "        aug_image = np.squeeze(aug_image_batch)\n",
        "        aug_image = aug_image.astype('int')\n",
        "        axs[i].imshow(aug_image)\n",
        "        axs[i].axis('off')"
      ],
      "metadata": {
        "id": "Vs5mn8Ty4Xyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ImageDataGenerator 변환 유형\n",
        "\n",
        "##### Flip\n",
        "- 좌우 반전: horizontal_flip = True\n",
        "- 상하 반전: vertical_flip = True\n",
        "\n",
        "##### Rotation\n",
        "- rotation_range = x\n",
        "- 임의의 -x ~ +x 사이 회전\n",
        "- 빈 공간은 fill_mode로 채워짐, default는 nearest\n",
        "\n",
        "##### Zoom\n",
        "- zoom_range = [0.5, 1.5]\n",
        "- 1보다 작은 값은 확장\n",
        "- 1보다 큰 값은 축소(빈 공간은 fill_mode로 채워짐, default는 nearest)\n",
        "\n",
        "##### Shift\n",
        "- 좌우 이동: width_shift_range = 0.2\n",
        "- 상하 이동: height_shift_range = 0.2\n",
        "- 0~1사이 값\n",
        "- 빈 공간은 fill_mode로 채워짐, default는 nearest\n",
        "\n",
        "##### Shear\n",
        "- shear_range = 45\n",
        "- X축 또는 y축 중심으로 0~45도 사이 변환\n",
        "\n",
        "##### Bright\n",
        "- brightness_range = (0.1, 0.9)\n",
        "- 밝기 조절, 0~1사이 값 입력, 0에 가까울수록 어둡고, 1에 가까울수록 밝음\n",
        "\n",
        "##### Channel Shift\n",
        "- channel_shift_range = x\n",
        "- R, G, B Pixel값을 -x ~ x 사이의 임의의 값을 더하여 변환, 0보다 작으면 0, 255보다 크면 255로 초기화\n",
        "\n",
        "##### Normalization\n",
        "- featurewise_center=True, 각 R, G, B Pixel 값에서 개별 채널 별 평균 Pixel값을 빼서 평균이 0이 되게 유지\n",
        "- featurewise_std_normalization=True 각 R, G, B Pixel값에서 개별 채널 별 표준 편차 Pixel값을 나눈다.\n",
        "- rescale = 1/255.0. 딥러닝은 입력이 비교적 작은 값을 선호하므로 0~255 -> 0~1\n"
      ],
      "metadata": {
        "id": "6urb0kfR9SMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(horizontal_flip=True)\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "BcBkgRuR4X1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(vertical_flip=True)\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "c34g5TwN4X6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "nssTU6s24X-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(rotation_range=45)\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "rAcakdym4YDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### fill_node의 파라미터 (default: nearest)\n",
        "\n",
        "- nearest: 주변 환경 그대로 가져옴\n",
        "- reflect: 거울 모드로 가져옴\n",
        "- wrap: 잘린 부분을 채움\n",
        "- constant: cval 파라미터 값으로 채움 (0 ~ 255, 0에 가까울수록 어두워진다.)"
      ],
      "metadata": {
        "id": "uuyrrrN_9Aj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(width_shift_range=0.4, fill_mode='nearest')\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "il-kwsfZ5ft9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(width_shift_range=0.4, fill_mode='reflect')\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "Zd6n1V6_5fyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(width_shift_range=0.4, fill_mode='wrap')\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "AzcDBvbR5f1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(width_shift_range=0.4, fill_mode='constant', cval=0)\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "Ap-QXfZp5f5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(shear_range=45)\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "gqQnzNK64YG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(zoom_range=[0.5, 0.9])\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "3e-7KcUc4YK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(zoom_range=[1.1, 1.5], fill_mode='constant', cval=0)\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "4uZE_2kE4YN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(brightness_range=(0.1, 0.9))\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "cdDOlskB7N0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(brightness_range=(1.0, 1.0))\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "zrrkTpeN8Yr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(brightness_range=(1.0, 2.0))\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "wZEDd3cP8Yvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(channel_shift_range=150)\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "dAEJYDbG8YyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " * keras의 ImageDataGenerator는 확률이 랜덤하게 적용"
      ],
      "metadata": {
        "id": "4Utffraa48PV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=(0.7, 1.3),\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    #rescale=1/255.0 # 학습시 적용, 시각화를 위해 임시로 주석처리\n",
        ")\n",
        "\n",
        "show_aug_image_batch(img, data_generator, n_images=4)"
      ],
      "metadata": {
        "id": "xgc9EwVi8Y1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YeRCMnsz8Y4c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}